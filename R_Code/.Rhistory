airquality = read.csv('AirQualityUCI.csv')
# replace -200 with NA
airquality[airquality == -200] <- NA
# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}
setwd(sourcedir)
# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]
# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam', ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))
# set airquality to imputed data
AQdata <- i$filled.dataset
# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
NO2.ts <- ts(dailyAQ$NO2.GT.)
autoplot(NO2.ts)
time.temp <- c(1:(length(NO2.ts)-7))
pg.NO2 <- spec.pgram(NO2.ts,spans=9,demean=T,log='no')
spec.NO2 <- data.frame(freq=pg.NO2$freq, spec=pg.NO2$spec)
max.omega.NO2 <- pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
max.omega.NO2
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
sorted.omega <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
#sorted.omega[1:20]
sorted.Ts[1:50]
NO2.season <- lm(NO2.ts[time.temp] ~ sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
summary(NO2.season)
e.NO2.season <- ts(NO2.season$residuals)
pg.e.NO2 <- spec.pgram(e.NO2.season,spans=9,demean=T,log='no')
spec.e.NO2 <- data.frame(freq=pg.e.NO2$freq, spec=pg.e.NO2$spec)
autoplot(e.NO2.season)
# Model diagnostics for temp.trend.seasonal
autoplot(NO2.season, which = c(1,2,4), labels.id = NULL)
ggAcf(e.NO2.season)
e.NO2.season.diff <- diff(e.NO2.season)
autoplot(e.NO2.season.diff)
ggAcf(e.NO2.season.diff)
ggPacf(e.NO2.season.diff)
ARIMA110 <- arima(e.NO2.season, c(1,1,0), include.mean = FALSE)
ARIMA012 <- arima(e.NO2.season, c(0,1,2), include.mean = FALSE)
ARIMA112 <- arima(e.NO2.season, c(1,1,2), include.mean = FALSE)
summary(ARIMA110)
summary(ARIMA012)
summary(ARIMA112)
NO2auto <- auto.arima(e.NO2.season, approximation = FALSE)
summary(NO2auto)
# assess residuals vs. fitted
model1 = ggplot() + geom_point(aes(x=fitted(ARIMA110), y=ARIMA110$residuals)) + ylim(-120,120) + xlim(-120,120) + ggtitle("ARIMA110")
model2 = ggplot() + geom_point(aes(x=fitted(ARIMA012), y=ARIMA012$residuals)) + ylim(-120,120) + xlim(-120,120) + ggtitle("ARIMA012")
model3 = ggplot() + geom_point(aes(x=fitted(ARIMA112), y=ARIMA112$residuals)) + ylim(-120,120) + xlim(-120,120) + ggtitle("ARIMA112")
ggarrange(model1, model2, model3, ncol=1, nrow=3)
# assess normality of residuals
model1 = qplot(sample=ARIMA110$residuals) + stat_qq_line(color="red") + ggtitle("ARIMA110")
model2 = qplot(sample=ARIMA012$residuals) + stat_qq_line(color="red") + ggtitle("ARIMA012")
model3 = qplot(sample=ARIMA112$residuals) + stat_qq_line(color="red") + ggtitle("ARIMA112")
ggarrange(model1, model2, model3, ncol=1, nrow=3)
ggtsdiag(ARIMA110, gof.lag = 20)
ggtsdiag(ARIMA012, gof.lag = 20)
ggtsdiag(ARIMA112, gof.lag = 20)
arima112.forecast <- forecast(ARIMA112, h = 7)
newtime.temp <- c((length(NO2.ts)-6):(length(NO2.ts)))
newdata <- data.frame(time.temp = newtime.temp, temp = NO2.ts[newtime.temp])
seasonal.pred <- predict(NO2.season, newdata = newdata)
next7daypred <- seasonal.pred + arima112.forecast$mean
mean((next7daypred - newdata$temp)^2)
arima012.forecast <- forecast(ARIMA012, h = 7)
next7daypred.2 <- seasonal.pred + arima012.forecast$mean
mean((next7daypred.2 - newdata$temp)^2)
arima110.forecast <- forecast(ARIMA110, h = 7)
next7daypred.2 <- seasonal.pred + arima110.forecast$mean
mean((next7daypred.2 - newdata$temp)^2)
plot(ts(newdata$temp), type = 'o', ylim = c(50,300))
lines(ts(next7daypred),col = 'red', type = 'o')
lines(1:7, seasonal.pred + arima012.forecast$lower[,2], col = 'red', lty = 'dashed')
lines(1:7, seasonal.pred + arima012.forecast$upper[,2], col = 'red', lty = 'dashed')
legend(1,60, legend = c('Actual', "Predicted"), lwd = 2, col = c('black', 'red'))
# Simulation
ARIMA012.sim <- arima.sim(n=365, list(order=c(0,1,2), ma=c(ARIMA012$coef[1],ARIMA012$coef[2])),
sd=sqrt(ARIMA012$sigma2))
# Add mean predictions and plot simulation of Tmin
time.yr <- c(1:365)
time.yr.df <- data.frame(time.temp = time.yr)
temp.yr.predictions <- predict(NO2.season, newdata=time.yr.df)
final.sim.ts = ts(temp.yr.predictions + ARIMA012.sim)
# plot simulated temperatures
time.temp.365 = c(1:365)
ggplot() + geom_line(aes(x=time.temp.365,y=final.sim.ts[1:length(time.temp.365)],color="Simulated")) +
geom_line(aes(x=time.temp.365,y=NO2.ts[1:length(time.temp.365)],color="Real")) + xlab("Time") +
ylab("Richmond Tmin")
require("knitr")
#MAKE SURE TO CHANGE
sourcedir <- "C:/Users/ucg8nb/OneDrive - University of Virginia/SYS 4021/R_Code"
datadir <- "C:/Users/ucg8nb/OneDrive - University of Virginia/SYS 4021/Data"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
library(ggplot2)
library(tidyverse)
library(lubridate)
library("car")
library(ggfortify)
library(ggpubr)
library(tseries)
set.seed(200)
setwd(datadir)
airquality = read.csv('AirQualityUCI.csv')
# replace -200 with NA
airquality[airquality == -200] <- NA
# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}
setwd(sourcedir)
# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]
# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam', ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))
# set airquality to imputed data
AQdata <- i$filled.dataset
# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
NO2.ts <- ts(dailyAQ$NO2.GT.)
autoplot(NO2.ts)
time.temp <- c(1:(length(NO2.ts)-7))
pg.NO2 <- spec.pgram(NO2.ts,spans=9,demean=T,log='no')
spec.NO2 <- data.frame(freq=pg.NO2$freq, spec=pg.NO2$spec)
max.omega.NO2 <- pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
max.omega.NO2
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
sorted.omega <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
#sorted.omega[1:20]
sorted.Ts[1:50]
NO2.season <- lm(NO2.ts[time.temp] ~ sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
summary(NO2.season)
e.NO2.season <- ts(NO2.season$residuals)
pg.e.NO2 <- spec.pgram(e.NO2.season,spans=9,demean=T,log='no')
spec.e.NO2 <- data.frame(freq=pg.e.NO2$freq, spec=pg.e.NO2$spec)
autoplot(e.NO2.season)
# Model diagnostics for temp.trend.seasonal
autoplot(NO2.season, which = c(1,2,4), labels.id = NULL)
ggAcf(e.NO2.season)
e.NO2.season.diff <- diff(e.NO2.season)
autoplot(e.NO2.season.diff)
ggAcf(e.NO2.season.diff)
ggPacf(e.NO2.season.diff)
ARIMA110 <- arima(e.NO2.season, c(1,1,0), include.mean = FALSE)
ARIMA012 <- arima(e.NO2.season, c(0,1,2), include.mean = FALSE)
ARIMA112 <- arima(e.NO2.season, c(1,1,2), include.mean = FALSE)
summary(ARIMA110)
summary(ARIMA012)
summary(ARIMA112)
NO2auto <- auto.arima(e.NO2.season, approximation = FALSE)
summary(NO2auto)
# assess residuals vs. fitted
model1 = ggplot() + geom_point(aes(x=fitted(ARIMA110), y=ARIMA110$residuals)) + ylim(-120,120) + xlim(-120,120) + ggtitle("ARIMA110")
model2 = ggplot() + geom_point(aes(x=fitted(ARIMA012), y=ARIMA012$residuals)) + ylim(-120,120) + xlim(-120,120) + ggtitle("ARIMA012")
model3 = ggplot() + geom_point(aes(x=fitted(ARIMA112), y=ARIMA112$residuals)) + ylim(-120,120) + xlim(-120,120) + ggtitle("ARIMA112")
ggarrange(model1, model2, model3, ncol=1, nrow=3)
# assess normality of residuals
model1 = qplot(sample=ARIMA110$residuals) + stat_qq_line(color="red") + ggtitle("ARIMA110")
model2 = qplot(sample=ARIMA012$residuals) + stat_qq_line(color="red") + ggtitle("ARIMA012")
model3 = qplot(sample=ARIMA112$residuals) + stat_qq_line(color="red") + ggtitle("ARIMA112")
ggarrange(model1, model2, model3, ncol=1, nrow=3)
ggtsdiag(ARIMA110, gof.lag = 20)
ggtsdiag(ARIMA012, gof.lag = 20)
ggtsdiag(ARIMA112, gof.lag = 20)
arima112.forecast <- forecast(ARIMA112, h = 7)
newtime.temp <- c((length(NO2.ts)-6):(length(NO2.ts)))
newdata <- data.frame(time.temp = newtime.temp, temp = NO2.ts[newtime.temp])
seasonal.pred <- predict(NO2.season, newdata = newdata)
next7daypred <- seasonal.pred + arima112.forecast$mean
mean((next7daypred - newdata$temp)^2)
arima012.forecast <- forecast(ARIMA012, h = 7)
next7daypred.2 <- seasonal.pred + arima012.forecast$mean
mean((next7daypred.2 - newdata$temp)^2)
arima110.forecast <- forecast(ARIMA110, h = 7)
next7daypred.2 <- seasonal.pred + arima110.forecast$mean
mean((next7daypred.2 - newdata$temp)^2)
plot(ts(newdata$temp), type = 'o', ylim = c(50,300))
lines(ts(next7daypred),col = 'red', type = 'o')
lines(1:7, seasonal.pred + arima012.forecast$lower[,2], col = 'red', lty = 'dashed')
lines(1:7, seasonal.pred + arima012.forecast$upper[,2], col = 'red', lty = 'dashed')
legend(1,60, legend = c('Actual', "Predicted"), lwd = 2, col = c('black', 'red'))
# Simulation
ARIMA012.sim <- arima.sim(n=365, list(order=c(0,1,2), ma=c(ARIMA012$coef[1],ARIMA012$coef[2])),
sd=sqrt(ARIMA012$sigma2))
# Add mean predictions and plot simulation of Tmin
time.yr <- c(1:365)
time.yr.df <- data.frame(time.temp = time.yr)
temp.yr.predictions <- predict(NO2.season, newdata=time.yr.df)
final.sim.ts = ts(temp.yr.predictions + ARIMA012.sim)
# plot simulated temperatures
time.temp.365 = c(1:365)
ggplot() + geom_line(aes(x=time.temp.365,y=final.sim.ts[1:length(time.temp.365)],color="Simulated")) +
geom_line(aes(x=time.temp.365,y=NO2.ts[1:length(time.temp.365)],color="Real")) + xlab("Time") +
ylab("Richmond Tmin")
time.trend <- c(1:length(NO2.ts))
NO2.season <- lm(NO2.ts[time.temp] ~ sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
pg.NO2.sim <- spec.pgram(final.sim.ts,spans=9,demean=T,log='no')
spec.NO2 <- data.frame(freq=pg.NO2.sim$freq, spec=pg.NO2.sim$spec)
pg.NO2.sim <- spec.pgram(final.sim.ts,spans=9,demean=T,log='no')
spec.NO2.sim <- data.frame(freq=pg.NO2.sim$freq, spec=pg.NO2.sim$spec)
sorted.spec <- sort(pg.NO2.sim$spec, decreasing=T, index.return=T)
sorted.omega <- pg.NO2.sim$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2.sim$freq[sorted.spec$ix]
#sorted.omega[1:20]
sorted.Ts[1:50]
time.trend <- c(1:length(NO2.ts))
NO2.trendseason <- lm(NO2.ts[time.temp] ~ time.trend + sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
time.temp <- c(1:(length(NO2.ts)))
NO2.trendseason <- lm(NO2.ts[time.temp] ~ time.trend + sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
pg.NO2.sim <- spec.pgram(final.sim.ts,spans=9,demean=T,log='no')
spec.NO2.sim <- data.frame(freq=pg.NO2.sim$freq, spec=pg.NO2.sim$spec)
sorted.spec <- sort(pg.NO2.sim$spec, decreasing=T, index.return=T)
sorted.omega <- pg.NO2.sim$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2.sim$freq[sorted.spec$ix]
#sorted.omega[1:20]
sorted.Ts[1:50]
NO2.season <- lm(NO2.ts[time.temp] ~ sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
NO2.trendseason.sim <- lm(final.sim.ts[time.temp] ~ sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
summary(NO2.trendseason)
summary(NO2.trendseason.sim)
NO2.trendseason.sim <- lm(final.sim.ts[time.temp] ~ time.temp sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
NO2.trendseason.sim <- lm(final.sim.ts[time.temp] ~ time.temp +  sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
summary(NO2.trendseason)
summary(NO2.trendseason.sim)
time.temp <- c(1:(length(NO2.ts)))
NO2.trendseason <- lm(NO2.ts[time.temp] ~ time.temp + sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
pg.NO2.sim <- spec.pgram(final.sim.ts,spans=9,demean=T,log='no')
spec.NO2.sim <- data.frame(freq=pg.NO2.sim$freq, spec=pg.NO2.sim$spec)
sorted.spec <- sort(pg.NO2.sim$spec, decreasing=T, index.return=T)
sorted.omega <- pg.NO2.sim$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2.sim$freq[sorted.spec$ix]
#sorted.omega[1:20]
sorted.Ts[1:50]
NO2.trendseason.sim <- lm(final.sim.ts[time.temp] ~ time.temp +  sin(2*pi*time.temp/7) + cos(2*pi*time.temp/7) + sin(2*pi*time.temp/3.5) + cos(2*pi*time.temp/3.5))
summary(NO2.trendseason)
summary(NO2.trendseason.sim)
ggAcf(final.sim.ts)
ggAcf(final.sim.ts)
ggAcf(NO2.ts)
datadir <- "C:/Users/ucg8nb/OneDrive - University of Virginia/SYS 4021/Data"
sourcedir <- "C:/Users/ucg8nb/OneDrive - University of Virginia/SYS 4021/R_Code"
#libraries
library(forecast)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(lattice)
library(psych)
library(dplyr)
library(mtsdi)
library(tidyverse)
library(ggfortify)
library(ggpubr)
library(tseries)
library("car")
library(here)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(ggfortify)
library(MASS)
library(lindia)
library(olsrr)
library(data.table)
library(plyr)
library(scales)
library(grid)
library(psych)
library(lattice)
library(car)
library(ggplot2)
library(ggpubr)
library(ggfortify)
library(ggResidpanel)
setwd(sourcedir)
source('AccidentInput.R')
source('PCAplots.R')
source("pc.glm.R")
source("ROC.R")
source("TestSet.R")
setwd(datadir)
houses <- read.table('housing-prices.csv', header = T, sep = ',')
setwd(sourcedir)
houses$Age
ggplot(houses, aes(Price)) + geom_boxplot()
pairs(~ Rooms + Baths + Size + Price, data = houses)
pairs.panels(houses[,c('Rooms', 'Baths', 'Size', 'Price')])
anova(houses.lm1, houses.fullmain)
houses.fullinteract <- lm(Price ~ (Baths + Rooms + Age + Size)^2, data = houses)
summary(houses.fullinteract)
houses.step = step(houses.fullinteract, trace = 0)
summary(houses.step)
AIC(houses.step)
autoplot(houses.step)
ols_test_breusch_pagan(houses.step)
houses[9,]
boxcox(houses.step)
L
datadir <- "C:/Users/ucg8nb/Downloads"
sourcedir <- "C:/Users/ucg8nb/OneDrive - University of Virginia/SYS 4021/R_Code"
#libraries
library(forecast)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(lattice)
library(psych)
library(dplyr)
library(mtsdi)
library(tidyverse)
library(ggfortify)
library(ggpubr)
library(tseries)
library("car")
library(here)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(ggfortify)
library(MASS)
library(lindia)
library(olsrr)
library(data.table)
library(plyr)
library(scales)
library(grid)
library(psych)
library(lattice)
library(car)
library(ggplot2)
library(ggpubr)
library(ggfortify)
library(ggResidpanel)
library(readxl)
setwd(sourcedir)
source('AccidentInput.R')
source('PCAplots.R')
source("pc.glm.R")
source("ROC.R")
source("TestSet.R")
setwd(datadir)
teamDataHit <- read_excel('SYS3034_Baseball_Data.xlsx', sheet = 'Team_Data_Hitting')
teamDataPitch <- read_excel('SYS3034_Baseball_Data.xlsx', sheet = 'Team_Data_Pitching')
playerData <- read_excel('SYS3034_Baseball_Data.xlsx', sheet = 'Player_Data')
teamDataHit$avgR = teamDataHit$R / teamDataHit$AB
teamDataHit$avgH = teamDataHit$H / teamDataHit$AB
teamDataHit$avg2B = teamDataHit$`2B` / teamDataHit$AB
teamDataHit$avg3B = teamDataHit$`3B` / teamDataHit$AB
teamDataHit$avgHR = teamDataHit$HR / teamDataHit$AB
teamDataHit$avgTB = teamDataHit$TB / teamDataHit$AB
teamDataHit$avgRBI = teamDataHit$RBI / teamDataHit$AB
simpleModel <- lm(W~. - TEAM - L - GP, data = teamDataHit)
summary(simpleModel)
stepModel = step(simpleModel, trace = 0)
summary(stepModel)
avgModel <- lm(W ~ . - TEAM - GP - L - R- H - `2B` - `3B` - HR - TB - RBI, data = teamDataHit)
summary(avgModel)
avgStepModel <- step(avgModel, trace= 0)
summary(avgStepModel)
AIC(stepModel)
AIC(avgStepModel)
fullTeamDf <- merge(teamDataHit, teamDataPitch, by = c('TEAM', 'GP', 'W', 'L'))
pitchingVar = c('ERA', 'SV', 'CG', 'SHO', 'IP', 'QS', 'ER', 'R', 'BB', 'So', 'BAA')
mainModel <- lm(W ~ . - TEAM - L - GP - R.x - R.y, data = fullTeamDf)
summary(mainModel)
mainStepModel <- step(mainModel, trace = 0)
summary(mainStepModel)
testModel <- ln(W ~ OBP + SLG + OPS, data = teamDataHit)
summary(testModel)
testModel <- lm(W ~ OBP + SLG + OPS, data = teamDataHit)
summary(testModel)
stepTest <- step(testModel)
summary(stepTest)
summary(mainStepModel)
avgModel <- lm(W ~ . - TEAM - GP - L - R- H - `2B` - `3B` - HR - TB - RBI, data = teamDataHit)
summary(avgModel)
avgStepModel <- step(avgModel, trace= 0)
summary(avgStepModel)
testModel <- lm(R ~ OBP + SLG + OPS, data = teamDataHit)
summary(testModel)
stepModel <- step(testModel, trace = 0)
summary(stepModel)
testModel <- lm(R ~ OBP + SLG + OPS + GP, data = teamDataHit)
summary(testModel)
stepModel <- step(testModel)
summary(stepModel)
testModel <- lm(R ~ OBP + SLG + OPS, data = teamDataHit)
summary(testModel)
stepModel <- step(testModel)
summary(stepModel)
testModel <- lm(R ~ OBP + SLG + OPS + GP, data = teamDataHit)
summary(testModel)
stepModel <- step(testModel)
summary(stepModel)
testModel <- lm(R ~ OBP + SLG + OPS + GP + AB, data = teamDataHit)
summary(testModel)
stepModel <- step(testModel)
summary(stepModel)
testModel <- lm(R ~ OBP + SLG + OPS + GP + AB + H + 2B + 3B, data = teamDataHit)
testModel <- lm(R ~ OBP + SLG + OPS + GP + AB + H, data = teamDataHit)
summary(testModel)
stepModel <- step(testModel)
summary(stepModel)
stepModel <- step(testModel, trace = 0)
summary(stepModel)
summary(testModel)
summary(mainStepModel)
mainStepModel <- step(mainModel, trace = 0)
summary(mainStepModel)
simpleModel <- lm(W~. - TEAM - L - GP, data = teamDataHit)
summary(simpleModel)
stepModel = step(simpleModel, trace = 0)
summary(stepModel)
teamDataHit <- read_excel('SYS3034_Baseball_Data.xlsx', sheet = 'Team_Data_Hitting')
simpleModel <- lm(W~. - TEAM - L - GP, data = teamDataHit)
summary(simpleModel)
stepModel = step(simpleModel, trace = 0)
summary(stepModel)
simpleModel <- lm(W~(. - TEAM - L - GP)^2, data = teamDataHit)
summary(simpleModel)
stepModel = step(simpleModel, trace = 0)
simpleModel <- lm(W~. - TEAM - L - GP, data = teamDataHit)
summary(simpleModel)
stepModel = step(simpleModel, trace = 0)
summary(stepModel)
autoplot(stepModel)
autoplot(stepModel)
autoplot(stepModel, which = 4)
#libraries
library(forecast)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(lattice)
library(psych)
library(dplyr)
library(mtsdi)
library(tidyverse)
library(ggfortify)
library(ggpubr)
library(tseries)
library("car")
library(here)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(ggfortify)
library(MASS)
library(lindia)
library(olsrr)
library(data.table)
library(plyr)
library(scales)
library(grid)
library(psych)
library(lattice)
library(car)
library(ggplot2)
library(ggpubr)
library(ggfortify)
library(ggResidpanel)
library(readxl)
setwd(sourcedir)
source('AccidentInput.R')
source('PCAplots.R')
source("pc.glm.R")
source("ROC.R")
source("TestSet.R")
autoplot(stepModel, which = 4)
ols_test_breusch_pagan(stepModel)
autoplot(stepModel)
autoplot(stepModel)
boxcox(stepModel)
library(ggfortify)
autoplot(stepModel, which = 1:6, ncol = 3, label.size = 3)
boxcox(stepModel)
main.transform <- lm(ln(W)~. - TEAM - L - GP, data = teamDataHit)
main.transform <- lm(log(W)~. - TEAM - L - GP, data = teamDataHit)
summary(main.transform)
transform.step <- step(main.transform, trace = 0)
summary(transform.step)
summary(stepModel)
autoplot(transform.step)
autoplot(transform.step, which = 1:6)
autoplot(transform.step, which = 1:6, ncols = 3)
autoplot(transform.step, which = 1:6, ncols = 3, label.size = 3)
autoplot(transform.step, which = 1:6, ncol = 3, label.size = 3)
library(ggfortify)
autoplot(transform.step, which = 1:6, ncol = 3, label.size = 3)
autoplot(stepModel, which = 1:6, ncol = 3, label.size = 3)
autoplot(stepModel, which = 1:6, ncol = 3, label.size = 3)
boxcox(stepModel)
boxcox(stepModel)
autoplot(stepModel, which = 1:6, ncol = 3, label.size = 3)
transform <- lm(log(W) ~ . - TEAM - L - GP, data = teamDataHit)
transform.step <- step(transform, trace = 0)
autoplot(transform.step, which = 1:6, ncol = 3, label.size = 3)
ols_test_breusch_pagan(transform.step)
summary(transform.step)
